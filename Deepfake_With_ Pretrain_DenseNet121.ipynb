{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca910524146492b84591287b4b3238f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "original_fake_paths = []\n",
    "\n",
    "for dirname, _, filenames in tqdm(os.walk('1-million-fake-faces/')):\n",
    "    for filename in filenames:\n",
    "        original_fake_paths.append([os.path.join(dirname, filename), filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'tmp/fake/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_paths = [save_dir + filename for _, filename in original_fake_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e805d18f1244465e89e8c1806ca31792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=160000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for path, filename in tqdm(original_fake_paths):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    cv2.imwrite(os.path.join(save_dir, filename), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake_paths, test_fake_paths = train_test_split(fake_paths, test_size=20000, random_state=2019)\n",
    "\n",
    "fake_train_df = pd.DataFrame(train_fake_paths, columns=['filename'])\n",
    "fake_train_df['class'] = 'FAKE'\n",
    "\n",
    "fake_test_df = pd.DataFrame(test_fake_paths, columns=['filename'])\n",
    "fake_test_df['class'] = 'FAKE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = 'celeba-dataset/img_align_celeba/img_align_celeba/'\n",
    "eval_partition = pd.read_csv('celeba-dataset/list_eval_partition.csv')\n",
    "\n",
    "eval_partition['filename'] = eval_partition.image_id.apply(lambda st: real_dir + st)\n",
    "eval_partition['class'] = 'REAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_df = eval_partition.query('partition in [0, 1]')[['filename', 'class']]\n",
    "real_test_df = eval_partition.query('partition == 2')[['filename', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([real_train_df, fake_train_df])\n",
    "test_df = pd.concat([real_test_df, fake_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 258110 validated image filenames belonging to 2 classes.\n",
      "Found 64527 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39962 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "    test_df,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights='densenet-keras/DenseNet-BC-121-32-no-top.h5',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in densenet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(densenet):\n",
    "    model = Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,305,281\n",
      "Trainable params: 265,217\n",
      "Non-trainable params: 7,040,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(densenet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4033 steps, validate for 1009 steps\n",
      "Epoch 1/3\n",
      "4033/4033 [==============================] - 1262s 313ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0326 - val_accuracy: 0.9892\n",
      "Epoch 2/3\n",
      "4033/4033 [==============================] - 1037s 257ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0150 - val_accuracy: 0.9953\n",
      "Epoch 3/3\n",
      "4033/4033 [==============================] - 963s 239ms/step - loss: 0.0014 - accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "train_history_step1 = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint],\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4033 steps, validate for 1009 steps\n",
      "Epoch 1/3\n",
      "4033/4033 [==============================] - 1004s 249ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 2/3\n",
      "4033/4033 [==============================] - 1023s 254ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "Epoch 3/3\n",
      "4033/4033 [==============================] - 1023s 254ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9983\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model.h5')\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "train_history_step2 = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=[checkpoint],\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(train_history_step2.history).to_csv('history2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
