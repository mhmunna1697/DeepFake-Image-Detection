{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from mtcnn==0.1.0) (4.1.2.30)\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from mtcnn==0.1.0) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from opencv-python>=4.1.0->mtcnn==0.1.0) (1.17.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.13.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (5.1.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->mtcnn==0.1.0) (1.1.0)\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/mtcnn-package/mtcnn-0.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import Model,Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/deepfake/metadata0.json',\n",
       " '../input/deepfake/metadata1.json',\n",
       " '../input/deepfake/metadata10.json',\n",
       " '../input/deepfake/metadata11.json',\n",
       " '../input/deepfake/metadata12.json',\n",
       " '../input/deepfake/metadata13.json',\n",
       " '../input/deepfake/metadata14.json',\n",
       " '../input/deepfake/metadata15.json',\n",
       " '../input/deepfake/metadata16.json',\n",
       " '../input/deepfake/metadata17.json',\n",
       " '../input/deepfake/metadata18.json',\n",
       " '../input/deepfake/metadata19.json',\n",
       " '../input/deepfake/metadata2.json',\n",
       " '../input/deepfake/metadata20.json',\n",
       " '../input/deepfake/metadata21.json',\n",
       " '../input/deepfake/metadata22.json',\n",
       " '../input/deepfake/metadata23.json',\n",
       " '../input/deepfake/metadata24.json',\n",
       " '../input/deepfake/metadata25.json',\n",
       " '../input/deepfake/metadata26.json',\n",
       " '../input/deepfake/metadata27.json',\n",
       " '../input/deepfake/metadata28.json',\n",
       " '../input/deepfake/metadata29.json',\n",
       " '../input/deepfake/metadata3.json',\n",
       " '../input/deepfake/metadata30.json',\n",
       " '../input/deepfake/metadata31.json',\n",
       " '../input/deepfake/metadata32.json',\n",
       " '../input/deepfake/metadata33.json',\n",
       " '../input/deepfake/metadata34.json',\n",
       " '../input/deepfake/metadata35.json',\n",
       " '../input/deepfake/metadata36.json',\n",
       " '../input/deepfake/metadata37.json',\n",
       " '../input/deepfake/metadata38.json',\n",
       " '../input/deepfake/metadata39.json',\n",
       " '../input/deepfake/metadata4.json',\n",
       " '../input/deepfake/metadata40.json',\n",
       " '../input/deepfake/metadata41.json',\n",
       " '../input/deepfake/metadata42.json',\n",
       " '../input/deepfake/metadata43.json',\n",
       " '../input/deepfake/metadata44.json',\n",
       " '../input/deepfake/metadata45.json',\n",
       " '../input/deepfake/metadata46.json',\n",
       " '../input/deepfake/metadata47.json',\n",
       " '../input/deepfake/metadata48.json',\n",
       " '../input/deepfake/metadata49.json',\n",
       " '../input/deepfake/metadata5.json',\n",
       " '../input/deepfake/metadata6.json',\n",
       " '../input/deepfake/metadata7.json',\n",
       " '../input/deepfake/metadata8.json',\n",
       " '../input/deepfake/metadata9.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob.glob('../input/deepfake/meta*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train0 = pd.read_json('../input/deepfake/metadata0.json')\n",
    "df_train1 = pd.read_json('../input/deepfake/metadata1.json')\n",
    "df_train2 = pd.read_json('../input/deepfake/metadata2.json')\n",
    "df_train3 = pd.read_json('../input/deepfake/metadata3.json')\n",
    "df_train4 = pd.read_json('../input/deepfake/metadata4.json')\n",
    "df_train5 = pd.read_json('../input/deepfake/metadata5.json')\n",
    "df_train6 = pd.read_json('../input/deepfake/metadata6.json')\n",
    "df_train7 = pd.read_json('../input/deepfake/metadata7.json')\n",
    "df_train8 = pd.read_json('../input/deepfake/metadata8.json')\n",
    "df_train9 = pd.read_json('../input/deepfake/metadata9.json')\n",
    "df_train10 = pd.read_json('../input/deepfake/metadata10.json')\n",
    "df_train11 = pd.read_json('../input/deepfake/metadata11.json')\n",
    "df_train12 = pd.read_json('../input/deepfake/metadata12.json')\n",
    "df_train13 = pd.read_json('../input/deepfake/metadata13.json')\n",
    "df_train14 = pd.read_json('../input/deepfake/metadata14.json')\n",
    "df_train15 = pd.read_json('../input/deepfake/metadata15.json')\n",
    "df_train16 = pd.read_json('../input/deepfake/metadata16.json')\n",
    "df_train17 = pd.read_json('../input/deepfake/metadata17.json')\n",
    "df_train18 = pd.read_json('../input/deepfake/metadata18.json')\n",
    "df_train19 = pd.read_json('../input/deepfake/metadata19.json')\n",
    "df_train20 = pd.read_json('../input/deepfake/metadata20.json')\n",
    "df_train21 = pd.read_json('../input/deepfake/metadata21.json')\n",
    "df_train22 = pd.read_json('../input/deepfake/metadata22.json')\n",
    "df_train23 = pd.read_json('../input/deepfake/metadata23.json')\n",
    "df_train24 = pd.read_json('../input/deepfake/metadata24.json')\n",
    "df_train25 = pd.read_json('../input/deepfake/metadata25.json')\n",
    "df_train26 = pd.read_json('../input/deepfake/metadata26.json')\n",
    "df_train27 = pd.read_json('../input/deepfake/metadata27.json')\n",
    "df_train28 = pd.read_json('../input/deepfake/metadata28.json')\n",
    "df_train29 = pd.read_json('../input/deepfake/metadata29.json')\n",
    "df_train30 = pd.read_json('../input/deepfake/metadata30.json')\n",
    "df_train31 = pd.read_json('../input/deepfake/metadata31.json')\n",
    "df_train32 = pd.read_json('../input/deepfake/metadata32.json')\n",
    "df_train33 = pd.read_json('../input/deepfake/metadata33.json')\n",
    "df_train34 = pd.read_json('../input/deepfake/metadata34.json')\n",
    "df_train35 = pd.read_json('../input/deepfake/metadata35.json')\n",
    "df_train36 = pd.read_json('../input/deepfake/metadata36.json')\n",
    "df_train37 = pd.read_json('../input/deepfake/metadata37.json')\n",
    "df_train38 = pd.read_json('../input/deepfake/metadata38.json')\n",
    "df_train39 = pd.read_json('../input/deepfake/metadata39.json')\n",
    "df_train40 = pd.read_json('../input/deepfake/metadata40.json')\n",
    "df_train41 = pd.read_json('../input/deepfake/metadata41.json')\n",
    "df_train42 = pd.read_json('../input/deepfake/metadata42.json')\n",
    "df_train43 = pd.read_json('../input/deepfake/metadata43.json')\n",
    "df_train44 = pd.read_json('../input/deepfake/metadata44.json')\n",
    "df_train45 = pd.read_json('../input/deepfake/metadata45.json')\n",
    "df_train46 = pd.read_json('../input/deepfake/metadata46.json')\n",
    "df_val1 = pd.read_json('../input/deepfake/metadata47.json')\n",
    "df_val2 = pd.read_json('../input/deepfake/metadata48.json')\n",
    "df_val3 = pd.read_json('../input/deepfake/metadata49.json')\n",
    "df_trains = [df_train0 ,df_train1, df_train2, df_train3, df_train4,\n",
    "             df_train5, df_train6, df_train7, df_train8, df_train9,df_train10,\n",
    "            df_train11, df_train12, df_train13, df_train14, df_train15,df_train16, \n",
    "            df_train17, df_train18, df_train19, df_train20, df_train21, df_train22, \n",
    "            df_train23, df_train24, df_train25, df_train26, df_train27, df_train28, \n",
    "            df_train29, df_train30, df_train31, df_train32, df_train33, df_train34,\n",
    "            df_train34, df_train35, df_train36, df_train37, df_train38, df_train39,\n",
    "            df_train40, df_train41, df_train42, df_train43, df_train44, df_train45,\n",
    "            df_train46]\n",
    "df_vals=[df_val1, df_val2, df_val3]\n",
    "nums = list(range(len(df_trains)+1))\n",
    "LABELS = ['REAL','FAKE']\n",
    "val_nums=[47, 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf7eef0d2aa4f0b8e044eeb886e8d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c97856551814707a6c461fe97f8457d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_path(num,x):\n",
    "    num=str(num)\n",
    "    if len(num)==2:\n",
    "        path='../input/deepfake/DeepFake'+num+'/DeepFake'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
    "    else:\n",
    "        path='../input/deepfake/DeepFake0'+num+'/DeepFake0'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
    "    if not os.path.exists(path):\n",
    "       raise Exception\n",
    "    return path\n",
    "paths=[]\n",
    "y=[]\n",
    "for df_train,num in tqdm(zip(df_trains,nums),total=len(df_trains)):\n",
    "    images = list(df_train.columns.values)\n",
    "    for x in images:\n",
    "        try:\n",
    "            paths.append(get_path(num,x))\n",
    "            y.append(LABELS.index(df_train[x]['label']))\n",
    "        except Exception as err:\n",
    "            #print(err)\n",
    "            pass\n",
    "\n",
    "val_paths=[]\n",
    "val_y=[]\n",
    "for df_val,num in tqdm(zip(df_vals,val_nums),total=len(df_vals)):\n",
    "    images = list(df_val.columns.values)\n",
    "    for x in images:\n",
    "        try:\n",
    "            val_paths.append(get_path(num,x))\n",
    "            val_y.append(LABELS.index(df_val[x]['label']))\n",
    "        except Exception as err:\n",
    "            #print(err)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64773 fake train samples\n",
      "There are 12130 real train samples\n",
      "There are 6108 fake val samples\n",
      "There are 1258 real val samples\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(y.count(1))+' fake train samples')\n",
    "print('There are '+str(y.count(0))+' real train samples')\n",
    "print('There are '+str(val_y.count(1))+' fake val samples')\n",
    "print('There are '+str(val_y.count(0))+' real val samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "real=[]\n",
    "fake=[]\n",
    "for m,n in zip(paths,y):\n",
    "    if n==0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake=random.sample(fake,len(real))\n",
    "paths,y=[],[]\n",
    "for x in real:\n",
    "    paths.append(x)\n",
    "    y.append(0)\n",
    "for x in fake:\n",
    "    paths.append(x)\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=[]\n",
    "fake=[]\n",
    "for m,n in zip(val_paths,val_y):\n",
    "    if n==0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake=random.sample(fake,len(real))\n",
    "val_paths,val_y=[],[]\n",
    "for x in real:\n",
    "    val_paths.append(x)\n",
    "    val_y.append(0)\n",
    "for x in fake:\n",
    "    val_paths.append(x)\n",
    "    val_y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12130 fake train samples\n",
      "There are 12130 real train samples\n",
      "There are 1258 fake val samples\n",
      "There are 1258 real val samples\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(y.count(1))+' fake train samples')\n",
    "print('There are '+str(y.count(0))+' real train samples')\n",
    "print('There are '+str(val_y.count(1))+' fake val samples')\n",
    "print('There are '+str(val_y.count(0))+' real val samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053d3c2c327449b6a3c209e0dbea129d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24260), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2ed71f91cc4ffaa7565e8e77e4d46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2516), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def read_img(path):\n",
    "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
    "X=[]\n",
    "for img in tqdm(paths):\n",
    "    X.append(read_img(img))\n",
    "val_X=[]\n",
    "for img in tqdm(val_paths):\n",
    "    val_X.append(read_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffle(X,y):\n",
    "    new_train=[]\n",
    "    for m,n in zip(X,y):\n",
    "        new_train.append([m,n])\n",
    "    random.shuffle(new_train)\n",
    "    X,y=[],[]\n",
    "    for x in new_train:\n",
    "        X.append(x[0])\n",
    "        y.append(x[1])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=shuffle(X,y)\n",
    "val_X,val_y=shuffle(val_X,val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionLayer(a, b, c, d):\n",
    "    def func(x):\n",
    "        x1 = Conv2D(a, (1, 1), padding='same', activation='elu')(x)\n",
    "        \n",
    "        x2 = Conv2D(b, (1, 1), padding='same', activation='elu')(x)\n",
    "        x2 = Conv2D(b, (3, 3), padding='same', activation='elu')(x2)\n",
    "            \n",
    "        x3 = Conv2D(c, (1, 1), padding='same', activation='elu')(x)\n",
    "        x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='elu')(x3)\n",
    "        \n",
    "        x4 = Conv2D(d, (1, 1), padding='same', activation='elu')(x)\n",
    "        x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='elu')(x4)\n",
    "        y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
    "            \n",
    "        return y\n",
    "    return func\n",
    "    \n",
    "def define_model(shape=(256,256,3)):\n",
    "    x = Input(shape = shape)\n",
    "    \n",
    "    x1 = InceptionLayer(1, 4, 4, 2)(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "    \n",
    "    x2 = InceptionLayer(2, 4, 4, 2)(x1)\n",
    "    x2 = BatchNormalization()(x2)        \n",
    "    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
    "        \n",
    "    x3 = Conv2D(16, (5, 5), padding='same', activation = 'elu')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "    x4 = Conv2D(16, (5, 5), padding='same', activation = 'elu')(x3)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    if shape==(256,256,3):\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "    else:\n",
    "        x4 = MaxPooling2D(pool_size=(2, 2), padding='same')(x4)\n",
    "    y = Flatten()(x4)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(16)(y)\n",
    "    y = LeakyReLU(alpha=0.1)(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(1, activation = 'sigmoid')(y)\n",
    "    model=Model(inputs = x, outputs = y)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-4))\n",
    "    #model.summary()\n",
    "    return model\n",
    "df_model=define_model()\n",
    "df_model.load_weights('../input/meso-pretrain/MesoInception_DF')\n",
    "f2f_model=define_model()\n",
    "f2f_model.load_weights('../input/meso-pretrain/MesoInception_F2F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "lrs=[1e-3,5e-4,1e-4]\n",
    "def schedule(epoch):\n",
    "    return lrs[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PRETRAIN=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 150, 150, 4)  16          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 150, 150, 4)  16          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 150, 150, 2)  8           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 150, 150, 1)  4           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 150, 150, 4)  148         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 150, 150, 4)  148         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 150, 150, 2)  38          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 150, 150, 11) 0           conv2d_33[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 150, 150, 11) 44          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 75, 75, 11)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 75, 75, 4)    48          max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 75, 75, 4)    48          max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 75, 75, 2)    24          max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 75, 75, 2)    24          max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 75, 75, 4)    148         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 75, 75, 4)    148         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 75, 75, 2)    38          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 75, 75, 12)   0           conv2d_40[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 75, 75, 12)   48          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 38, 38, 12)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 38, 38, 16)   4816        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 38, 38, 16)   64          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 19, 19, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 19, 19, 16)   6416        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 19, 19, 16)   64          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 10, 10, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1600)         0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1600)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           25616       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16)           0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            17          dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 37,941\n",
      "Trainable params: 37,831\n",
      "Non-trainable params: 110\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 39s 2ms/step - loss: 0.7163\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6450\n",
      "fold 0 model loss: 0.633397108791929\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 35s 1ms/step - loss: 0.7059\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6429\n",
      "fold 1 model loss: 0.6466134329858001\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 34s 1ms/step - loss: 0.7033\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6430\n",
      "fold 2 model loss: 0.6593701248782701\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 35s 1ms/step - loss: 0.7257\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6483\n",
      "fold 3 model loss: 0.6494618990815383\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 34s 1ms/step - loss: 0.7206\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 32s 1ms/step - loss: 0.6451\n",
      "fold 4 model loss: 0.664477240870187\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 35s 1ms/step - loss: 0.7105\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 32s 1ms/step - loss: 0.6361\n",
      "fold 0 model loss: 0.6367635362649622\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 35s 1ms/step - loss: 0.7328\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6450\n",
      "fold 1 model loss: 0.6599882225491571\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 34s 1ms/step - loss: 0.7137\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6422\n",
      "fold 2 model loss: 0.6575619084405193\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 35s 1ms/step - loss: 0.7336\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 33s 1ms/step - loss: 0.6461\n",
      "fold 3 model loss: 0.662093652113206\n",
      "Epoch 1/2\n",
      "24260/24260 [==============================] - 34s 1ms/step - loss: 0.7052\n",
      "Epoch 2/2\n",
      "24260/24260 [==============================] - 32s 1ms/step - loss: 0.6343\n",
      "fold 4 model loss: 0.636956200199855\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "kfolds=5\n",
    "losses=[]\n",
    "if LOAD_PRETRAIN:\n",
    "    # import keras.backend as K\n",
    "    df_models=[]\n",
    "    f2f_models=[]\n",
    "    i=0\n",
    "    while len(df_models)<kfolds:\n",
    "        model=define_model((150,150,3))\n",
    "        if i==0:\n",
    "            model.summary()\n",
    "        #model.load_weights('../input/meso-pretrain/MesoInception_DF')\n",
    "        for new_layer, layer in zip(model.layers[1:-8], df_model.layers[1:-8]):\n",
    "            new_layer.set_weights(layer.get_weights())\n",
    "        model.fit([X],[y],epochs=2,callbacks=[LearningRateScheduler(schedule)])\n",
    "        pred=model.predict([val_X])\n",
    "        loss=log_loss(val_y,pred)\n",
    "        losses.append(loss)\n",
    "        print('fold '+str(i)+' model loss: '+str(loss))\n",
    "        df_models.append(model)\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        i+=1\n",
    "    i=0\n",
    "    while len(f2f_models)<kfolds:\n",
    "        model=define_model((150,150,3))\n",
    "        #model.load_weights('../input/meso-pretrain/MesoInception_DF')\n",
    "        for new_layer, layer in zip(model.layers[1:-8], f2f_model.layers[1:-8]):\n",
    "            new_layer.set_weights(layer.get_weights())\n",
    "        model.fit([X],[y],epochs=2,callbacks=[LearningRateScheduler(schedule)])\n",
    "        pred=model.predict([val_X])\n",
    "        loss=log_loss(val_y,pred)\n",
    "        losses.append(loss)\n",
    "        print('fold '+str(i)+' model loss: '+str(loss))\n",
    "        f2f_models.append(model)\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        i+=1\n",
    "        models=f2f_models+df_models\n",
    "else:\n",
    "    models=[]\n",
    "    i=0\n",
    "    while len(models)<kfolds:\n",
    "        model=define_model((150,150,3))\n",
    "        if i==0:\n",
    "            model.summary()\n",
    "        model.fit([X],[y],epochs=2,callbacks=[LearningRateScheduler(schedule)])\n",
    "        pred=model.predict([val_X])\n",
    "        loss=log_loss(val_y,pred)\n",
    "        losses.append(loss)\n",
    "        print('fold '+str(i)+' model loss: '+str(loss))\n",
    "        if loss<0.68:\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print('loss too bad, retrain!')\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Because of the smaller input size, this code:\n",
    "```\n",
    "    for new_layer, layer in zip(model.layers[1:-8], f2f_model.layers[1:-8]):\n",
    "        new_layer.set_weights(layer.get_weights())\n",
    "```\n",
    "fetches only the conv layers weight and apply it onto our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_pipline(X,two_times=False):\n",
    "    preds=[]\n",
    "    for model in tqdm(models):\n",
    "        pred=model.predict([X])\n",
    "        preds.append(pred)\n",
    "    preds=sum(preds)/len(preds)\n",
    "    if two_times:\n",
    "        return larger_range(preds,2)\n",
    "    else:\n",
    "        return preds\n",
    "def larger_range(model_pred,time):\n",
    "    return (((model_pred-0.5)*time)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pred=models[losses.index(min(losses))].predict([val_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511ebfca25014ed6984f1ef8358b4cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_pred=prediction_pipline(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some baselines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random loss: 0.7256620055750759\n",
      "1 loss: 17.26978799617044\n",
      "0 loss: 17.269388197455342\n",
      "0.5 loss: 0.6931471805599454\n"
     ]
    }
   ],
   "source": [
    "random_pred=np.random.random(len(val_X))\n",
    "print('random loss: ' + str(log_loss(val_y,random_pred.clip(0.35,0.65))))\n",
    "allone_pred=np.array([1 for _ in range(len(val_X))])\n",
    "print('1 loss: ' + str(log_loss(val_y,allone_pred)))\n",
    "allzero_pred=np.array([0 for _ in range(len(val_X))])\n",
    "print('0 loss: ' + str(log_loss(val_y,allzero_pred)))\n",
    "allpoint5_pred=np.array([0.5 for _ in range(len(val_X))])\n",
    "print('0.5 loss: ' + str(log_loss(val_y,allpoint5_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Averaging Loss: 0.6460706926586139\n",
      "Two Times Larger Range(Averaging) Loss: 0.6460170364673642\n",
      "Best Single Model Loss: 0.648418484578451\n",
      "Two Times Larger Range(Single Model) Loss: 0.6489442478397502\n",
      "two times larger range is better\n"
     ]
    }
   ],
   "source": [
    "print('Simple Averaging Loss: '+str(log_loss(val_y,model_pred.clip(0.35,0.65))))\n",
    "print('Two Times Larger Range(Averaging) Loss: '+str(log_loss(val_y,larger_range(model_pred,2).clip(0.35,0.65))))\n",
    "print('Best Single Model Loss: '+str(log_loss(val_y,best_model_pred.clip(0.35,0.65))))\n",
    "print('Two Times Larger Range(Single Model) Loss: '+str(log_loss(val_y,larger_range(best_model_pred,2).clip(0.35,0.65))))\n",
    "if log_loss(val_y,model_pred.clip(0.35,0.65))<log_loss(val_y,larger_range(model_pred,2).clip(0.35,0.65)):\n",
    "    two_times=False\n",
    "    print('simple averaging is better')\n",
    "else:\n",
    "    two_times=True\n",
    "    print('two times larger range is better')\n",
    "two_times=False #This is not a bug. I did this intentionally because the model can't get most of the private validation set right(based on LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52389145\n",
      "0.122150324\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(model_pred.clip(0.35,0.65).mean())\n",
    "print(scipy.stats.median_absolute_deviation(model_pred.clip(0.35,0.65))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct ✅  prediction: 0.841267, answer: 1\n",
      "incorrect❌ prediction: 0.3926074, answer: 1\n",
      "correct ✅  prediction: 0.4687201, answer: 0\n",
      "incorrect❌ prediction: 0.4125269, answer: 1\n",
      "correct ✅  prediction: 0.63050485, answer: 1\n",
      "correct ✅  prediction: 0.4828743, answer: 0\n",
      "correct ✅  prediction: 0.6945424, answer: 1\n",
      "correct ✅  prediction: 0.52097714, answer: 1\n",
      "correct ✅  prediction: 0.60750103, answer: 1\n",
      "correct ✅  prediction: 0.31545845, answer: 0\n",
      "incorrect❌ prediction: 0.48146382, answer: 1\n",
      "incorrect❌ prediction: 0.62090313, answer: 0\n",
      "correct ✅  prediction: 0.42533535, answer: 0\n",
      "correct ✅  prediction: 0.8625847, answer: 1\n",
      "incorrect❌ prediction: 0.33781263, answer: 1\n",
      "incorrect❌ prediction: 0.54614687, answer: 0\n",
      "correct ✅  prediction: 0.3734336, answer: 0\n",
      "number correct: 1584, number incorrect: 932\n",
      "63.0% correct, 37.0% incorrect\n"
     ]
    }
   ],
   "source": [
    "def check_answers(pred,real,num):\n",
    "    for i,(x,y) in enumerate(zip(pred,real)):\n",
    "        correct_incorrect='correct ✅ ' if round(float(x),0)==round(float(y),0) else 'incorrect❌'\n",
    "        print(correct_incorrect+' prediction: '+str(x[0])+', answer: '+str(y))\n",
    "        if i>num:\n",
    "            return\n",
    "def correct_precentile(pred,real):\n",
    "    correct=0\n",
    "    incorrect=0\n",
    "    for x,y in zip(pred,real):\n",
    "        if round(float(x),0)==round(float(y),0):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "    print('number correct: '+str(correct)+', number incorrect: '+str(incorrect))\n",
    "    print(str(round(correct/len(real)*100,1))+'% correct'+', '+str(round(incorrect/len(real)*100,1))+'% incorrect')\n",
    "check_answers(model_pred,val_y,15)\n",
    "correct_precentile(model_pred,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,y,val_X,val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad31ca201601491399244909183e62c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "no faces found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SKIP=10\n",
    "NUM_FRAME=150\n",
    "test_dir = '/kaggle/input/deepfake-detection-challenge/test_videos/'\n",
    "filenames = os.listdir(test_dir)\n",
    "prediction_filenames = filenames\n",
    "test_video_files = [test_dir + x for x in filenames]\n",
    "detector = MTCNN()\n",
    "def detect_face(img):\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    final = []\n",
    "    detected_faces_raw = detector.detect_faces(img)\n",
    "    if detected_faces_raw==[]:\n",
    "        #print('no faces found')\n",
    "        return []\n",
    "    confidences=[]\n",
    "    for n in detected_faces_raw:\n",
    "        x,y,w,h=n['box']\n",
    "        final.append([x,y,w,h])\n",
    "        confidences.append(n['confidence'])\n",
    "    if max(confidences)<0.9:\n",
    "        return []\n",
    "    max_conf_coord=final[confidences.index(max(confidences))]\n",
    "    #return final\n",
    "    return max_conf_coord\n",
    "def crop(img,x,y,w,h):\n",
    "    x-=40\n",
    "    y-=40\n",
    "    w+=80\n",
    "    h+=80\n",
    "    if x<0:\n",
    "        x=0\n",
    "    if y<=0:\n",
    "        y=0\n",
    "    return cv2.cvtColor(cv2.resize(img[y:y+h,x:x+w],(150,150)),cv2.COLOR_BGR2RGB)\n",
    "def detect_video(video):\n",
    "    v_cap = cv2.VideoCapture(video)\n",
    "    v_cap.set(1, NUM_FRAME)\n",
    "    success, vframe = v_cap.read()\n",
    "    vframe = cv2.cvtColor(vframe, cv2.COLOR_BGR2RGB)\n",
    "    bounding_box=detect_face(vframe)\n",
    "    if bounding_box==[]:\n",
    "        count=0\n",
    "        current=NUM_FRAME\n",
    "        while bounding_box==[] and count<MAX_SKIP:\n",
    "            current+=1\n",
    "            v_cap.set(1,current)\n",
    "            success, vframe = v_cap.read()\n",
    "            vframe = cv2.cvtColor(vframe, cv2.COLOR_BGR2RGB)\n",
    "            bounding_box=detect_face(vframe)\n",
    "            count+=1\n",
    "        if bounding_box==[]:\n",
    "            print('no faces found')\n",
    "            prediction_filenames.remove(video.replace('/kaggle/input/deepfake-detection-challenge/test_videos/',''))\n",
    "            return None\n",
    "    x,y,w,h=bounding_box\n",
    "    v_cap.release()\n",
    "    return crop(vframe,x,y,w,h)\n",
    "test_X = []\n",
    "for video in tqdm(test_video_files):\n",
    "    x=detect_video(video)\n",
    "    if x is None:\n",
    "        continue\n",
    "    test_X.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc5d30b69a14f578927d279ecc34fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv('/kaggle/input/deepfake-detection-challenge/sample_submission.csv')\n",
    "df_test['label']=0.5\n",
    "preds=prediction_pipline(test_X,two_times=two_times).clip(0.35,0.65)\n",
    "for pred,name in zip(preds,prediction_filenames):\n",
    "    name=name.replace('/kaggle/input/deepfake-detection-challenge/test_videos/','')\n",
    "    df_test.iloc[list(df_test['filename']).index(name),1]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5727\n",
      "0.06182593\n",
      "[[0.51568985]\n",
      " [0.35621387]\n",
      " [0.65      ]\n",
      " [0.3742422 ]\n",
      " [0.35      ]\n",
      " [0.65      ]\n",
      " [0.43442696]\n",
      " [0.65      ]\n",
      " [0.65      ]\n",
      " [0.5413329 ]]\n"
     ]
    }
   ],
   "source": [
    "print(preds.clip(0.35,0.65).mean())\n",
    "print(scipy.stats.median_absolute_deviation(preds.clip(0.35,0.65))[0])\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aassnaulhq.mp4</td>\n",
       "      <td>0.553683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aayfryxljh.mp4</td>\n",
       "      <td>0.470718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acazlolrpz.mp4</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adohdulfwb.mp4</td>\n",
       "      <td>0.471218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahjnxtiamx.mp4</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename     label\n",
       "0  aassnaulhq.mp4  0.553683\n",
       "1  aayfryxljh.mp4  0.470718\n",
       "2  acazlolrpz.mp4  0.650000\n",
       "3  adohdulfwb.mp4  0.471218\n",
       "4  ahjnxtiamx.mp4  0.350000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
